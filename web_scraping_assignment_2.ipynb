{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Q1: Write a  program to scrape data for “Data Analyst” Job position in“Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function\n",
    "def jobs_data_ana_sci(job_position, webdriver_path):\n",
    "    # initializing web driver and webpage\n",
    "    driver  = webdriver.Chrome(webdriver_path)\n",
    "    driver.get('https://www.naukri.com/')\n",
    "    # search job position and location\n",
    "    driver.find_element_by_id('qsb-keyword-sugg').send_keys(job_position)\n",
    "    driver.find_element_by_id('qsb-location-sugg').send_keys('Bangalore')\n",
    "    driver.find_element_by_class_name('search-btn').click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # extracting 'job_title', 'company', 'location','experience' and salary for first 10 jobs\n",
    "    bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    job_info = bs.find_all('div', attrs ={'class':'jobTupleHeader'})[:10]\n",
    "    job_title = [j.text for i in job_info for j in i.find_all('a','title fw500 ellipsis')]\n",
    "    company = [j.text for i in job_info for j in i.find_all('a','subTitle ellipsis fleft')]\n",
    "    location = [j.text for i in job_info for j in i.find_all('li','fleft grey-text br2 placeHolderLi location')]\n",
    "    experience = [j.text for i in job_info for j in i.find_all('li','fleft grey-text br2 placeHolderLi experience')]\n",
    "    salary = [j.find('span','ellipsis fleft fs12 lh16').get_text() for i in job_info for j in i.find_all('li','fleft grey-text br2 placeHolderLi salary')]\n",
    "\n",
    "    # extracting job page url for each job\n",
    "    jobs_url = bs.find_all('a', attrs ={'class':'title fw500 ellipsis'})\n",
    "    \n",
    "    # extracting job description correspounding to each job url.\n",
    "    job_decr = []\n",
    "    for i in jobs_url[:10]:\n",
    "                driver.get(i['href'])\n",
    "                bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                try:\n",
    "                    job_decr.append(bs.find('section','job-desc').text)\n",
    "                except AttributeError:\n",
    "                    try:\n",
    "                        job_decr.append(bs.find('section','JD av_textblock_section').text.replace('\\n',' '))\n",
    "                    except AttributeError:\n",
    "                        try:\n",
    "                            job_decr.append(bs.find('div','ptb20 hLine').text.replace('\\n',' '))\n",
    "                        except:\n",
    "                            job_decr.append('-')\n",
    "\n",
    "\n",
    "    job_df = pd.DataFrame({'Job_title':job_title,\n",
    "                                  'Company':company,\n",
    "                                  'Location': location,\n",
    "                                  'Experience':experience,\n",
    "                                  'Salary': salary,\n",
    "                                  'Job_description':job_decr \n",
    "                          })\n",
    "    return job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher  Data Engineer / Data Scientist / Data...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesAnaly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Job description Dear Candidate  Schedule a Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description   Job Summary:    Data Analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAS AML Data Analyst / Trainee &amp; Data Science,...</td>\n",
       "      <td>MagicBase Royal BD Pvt Ltd</td>\n",
       "      <td>Bengaluru(Whitefield)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>50,000 - 2,00,000 PA.</td>\n",
       "      <td>Job descriptionWe are looking to hire SAS Anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>3,00,000 - 6,00,000 PA.</td>\n",
       "      <td>Job description Hiring Data Analyst profile on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>2,50,000 - 5,50,000 PA.</td>\n",
       "      <td>Job description Flipkart is looking for Data A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    Roles and ResponsibilitiesS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Study Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    Roles and ResponsibilitiesA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognizant Technology Solutions India Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    Roles and ResponsibilitiesT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>10-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job description    Project   Description    Fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Fresher  Data Engineer / Data Scientist / Data...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2                              Business Data Analyst   \n",
       "3  SAS AML Data Analyst / Trainee & Data Science,...   \n",
       "4                               Hiring Data Analysts   \n",
       "5                               Hiring Data Analysts   \n",
       "6                                       Data Analyst   \n",
       "7                                 Study Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                             Company  \\\n",
       "0                     ACHYUTAS SOFT PRIVATE LIMITED    \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                                             NetApp   \n",
       "3                         MagicBase Royal BD Pvt Ltd   \n",
       "4                  Flipkart Internet Private Limited   \n",
       "5                  Flipkart Internet Private Limited   \n",
       "6            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "7            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8           Cognizant Technology Solutions India Ltd   \n",
       "9                                             Luxoft   \n",
       "\n",
       "                              Location Experience                   Salary  \\\n",
       "0      Delhi NCR, Bengaluru, Hyderabad    0-2 Yrs  3,50,000 - 8,50,000 PA.   \n",
       "1  Chennai, Pune, Bengaluru, Hyderabad    0-3 Yrs  3,50,000 - 4,50,000 PA.   \n",
       "2                            Bengaluru    2-3 Yrs            Not disclosed   \n",
       "3                Bengaluru(Whitefield)    0-5 Yrs    50,000 - 2,00,000 PA.   \n",
       "4                            Bengaluru    2-5 Yrs  3,00,000 - 6,00,000 PA.   \n",
       "5                            Bengaluru    2-5 Yrs  2,50,000 - 5,50,000 PA.   \n",
       "6                     Bengaluru, India    3-5 Yrs            Not disclosed   \n",
       "7                            Bengaluru    4-8 Yrs            Not disclosed   \n",
       "8                            Bengaluru    3-4 Yrs            Not disclosed   \n",
       "9                            Bengaluru  10-12 Yrs            Not disclosed   \n",
       "\n",
       "                                     Job_description  \n",
       "0  Job descriptionRoles and ResponsibilitiesAnaly...  \n",
       "1  Job description Dear Candidate  Schedule a Tel...  \n",
       "2   Job Description   Job Summary:    Data Analys...  \n",
       "3  Job descriptionWe are looking to hire SAS Anal...  \n",
       "4  Job description Hiring Data Analyst profile on...  \n",
       "5  Job description Flipkart is looking for Data A...  \n",
       "6  Job Description    Roles and ResponsibilitiesS...  \n",
       "7  Job Description    Roles and ResponsibilitiesA...  \n",
       "8  Job Description    Roles and ResponsibilitiesT...  \n",
       "9  Job description    Project   Description    Fe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling function 'jobs_data_ana_sci' for scraping 'Data Analyst' jobs data at 'Bangalore'\n",
    "jobs_data_ana_sci(job_position = 'Data Analyst', webdriver_path = r'C:\\Users\\91743\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Write a  program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher  Data Engineer / Data Scientist / Data...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesAnaly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Job description Dear Candidate  Schedule a Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Python/MATLAB/Machine Learnin...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesData ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/Data Mi...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesRequi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning/Data Mining</td>\n",
       "      <td>Minions Ventures</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionKey Responsibilities :- Use ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    The Yantriks Data Science a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesSkill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Job descriptionRoles and Responsibilities  Mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Job descriptionRoles and Responsibilities  Mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist  -  Machine Learning -  Remote ...</td>\n",
       "      <td>Doji Ltd</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>15,00,000 - 20,00,000 PA.</td>\n",
       "      <td>Job descriptionPlease note that this role will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Fresher  Data Engineer / Data Scientist / Data...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2  Data Scientist - Python/MATLAB/Machine Learnin...   \n",
       "3  Lead Data Scientist - Machine Learning/Data Mi...   \n",
       "4      Data Scientist - Machine Learning/Data Mining   \n",
       "5                  Data Scientist - Machine Learning   \n",
       "6             Senior Data Scientist - NLP/ Python/ R   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9  Data Scientist  -  Machine Learning -  Remote ...   \n",
       "\n",
       "                                             Company  \\\n",
       "0                     ACHYUTAS SOFT PRIVATE LIMITED    \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                       Wrackle Technologies Pvt Ltd   \n",
       "3                       Wrackle Technologies Pvt Ltd   \n",
       "4                                   Minions Ventures   \n",
       "5                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "6                                 AVI Consulting LLP   \n",
       "7                                           CES Ltd.   \n",
       "8                                           CES Ltd.   \n",
       "9                                           Doji Ltd   \n",
       "\n",
       "                                            Location Experience  \\\n",
       "0                    Delhi NCR, Bengaluru, Hyderabad    0-2 Yrs   \n",
       "1                Chennai, Pune, Bengaluru, Hyderabad    0-3 Yrs   \n",
       "2                                          Bengaluru    3-8 Yrs   \n",
       "3                                          Bengaluru   6-11 Yrs   \n",
       "4                                          Bengaluru    6-8 Yrs   \n",
       "5                                          Bengaluru    2-7 Yrs   \n",
       "6                               Bengaluru, Hyderabad    4-9 Yrs   \n",
       "7  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...    2-7 Yrs   \n",
       "8  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...    2-7 Yrs   \n",
       "9            Delhi NCR, Bengaluru, Anywhere in India    2-5 Yrs   \n",
       "\n",
       "                      Salary  \\\n",
       "0    3,50,000 - 8,50,000 PA.   \n",
       "1    3,50,000 - 4,50,000 PA.   \n",
       "2              Not disclosed   \n",
       "3              Not disclosed   \n",
       "4              Not disclosed   \n",
       "5              Not disclosed   \n",
       "6              Not disclosed   \n",
       "7   7,00,000 - 15,00,000 PA.   \n",
       "8   7,00,000 - 15,00,000 PA.   \n",
       "9  15,00,000 - 20,00,000 PA.   \n",
       "\n",
       "                                     Job_description  \n",
       "0  Job descriptionRoles and ResponsibilitiesAnaly...  \n",
       "1  Job description Dear Candidate  Schedule a Tel...  \n",
       "2  Job descriptionRoles and ResponsibilitiesData ...  \n",
       "3  Job descriptionRoles and ResponsibilitiesRequi...  \n",
       "4  Job descriptionKey Responsibilities :- Use ana...  \n",
       "5  Job Description    The Yantriks Data Science a...  \n",
       "6  Job descriptionRoles and ResponsibilitiesSkill...  \n",
       "7  Job descriptionRoles and Responsibilities  Mus...  \n",
       "8  Job descriptionRoles and Responsibilities  Mus...  \n",
       "9  Job descriptionPlease note that this role will...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling function 'jobs_data_ana_sci' for scraping 'Data Scientist' jobs data at 'Bangalore'\n",
    "jobs_data_ana_sci(job_position = 'Data Scientist', webdriver_path = r'C:\\Users\\91743\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: Write a program to scrape job data using the filters 'Location' and 'Salary'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher  Data Engineer / Data Scientist / Data...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PureSoftware Pvt Ltd.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Stark Industries</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Job | Opportunity For Senior Role(Data Scienti...</td>\n",
       "      <td>BA Continuum India Pvt. Ltd</td>\n",
       "      <td>Gandhinagar, Delhi NCR, Mumbai, Gurgaon</td>\n",
       "      <td>14-17 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist For A Leading Movers &amp; Packers ...</td>\n",
       "      <td>Myfuture Placement Consultancy</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist(Hadoop/ Redshift /BigQuery)</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>Noida</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Fresher  Data Engineer / Data Scientist / Data...   \n",
       "1  GCP Skilled Analytics Resources (Data engineer...   \n",
       "2  GCP Skilled Analytics Resources (Data engineer...   \n",
       "3           Data Scientist - Python/Machine Learning   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7  Job | Opportunity For Senior Role(Data Scienti...   \n",
       "8  Data Scientist For A Leading Movers & Packers ...   \n",
       "9         Data Scientist(Hadoop/ Redshift /BigQuery)   \n",
       "\n",
       "                              Company  \\\n",
       "0      ACHYUTAS SOFT PRIVATE LIMITED    \n",
       "1  Aerial Telecom Solutions Pvt. Ltd.   \n",
       "2  Aerial Telecom Solutions Pvt. Ltd.   \n",
       "3                               Jubna   \n",
       "4               PureSoftware Pvt Ltd.   \n",
       "5               World Wide Technology   \n",
       "6                    Stark Industries   \n",
       "7         BA Continuum India Pvt. Ltd   \n",
       "8     Myfuture Placement Consultancy    \n",
       "9                               Jubna   \n",
       "\n",
       "                                  Location Experience  \n",
       "0          Delhi NCR, Bengaluru, Hyderabad    0-2 Yrs  \n",
       "1                 Pune, Bengaluru, Gurgaon    3-8 Yrs  \n",
       "2                 Pune, Bengaluru, Gurgaon    3-8 Yrs  \n",
       "3                                    Noida    5-8 Yrs  \n",
       "4                                  Gurgaon    5-9 Yrs  \n",
       "5                                  Gurgaon    3-8 Yrs  \n",
       "6                                    Delhi    3-5 Yrs  \n",
       "7  Gandhinagar, Delhi NCR, Mumbai, Gurgaon  14-17 Yrs  \n",
       "8                                Delhi NCR    1-2 Yrs  \n",
       "9                                    Noida    4-6 Yrs  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.naukri.com/')\n",
    " # search job position\n",
    "driver.find_element_by_id('qsb-keyword-sugg').send_keys('Data Scientist')\n",
    "driver.find_element_by_class_name('search-btn').click()\n",
    "time.sleep(3)\n",
    "# check location as 'Delhi/NCR' and salary as '3-6 lakhs'\n",
    "driver.find_element_by_xpath('//label[@class=\"chkLbl\" and @for = \"chk-Delhi/NCR-cityType-\"]/i').click()\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//label[@class=\"chkLbl\" and @for = \"chk-3-6 Lakhs-ctcFilter-\"]/i').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# extracting 'job_title', 'company', 'location' and 'experience' for first 10 jobs\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "jobs = bs.find_all('div', attrs ={'class':'jobTupleHeader'})[:10]\n",
    "job_title = [j.text for i in jobs for j in i.find_all('a','title fw500 ellipsis')]\n",
    "company = [j.text for i in jobs for j in i.find_all('a','subTitle ellipsis fleft')]\n",
    "location = [j.get_text() for i in jobs for j in i.find_all('li','fleft grey-text br2 placeHolderLi location')]\n",
    "experience = [j.get_text() for i in jobs for j in i.find_all('li','fleft grey-text br2 placeHolderLi experience')]\n",
    "\n",
    "job_df = pd.DataFrame({'Job_title':job_title,\n",
    "                       'Company':company,\n",
    "                       'Location': location,\n",
    "                       'Experience':experience,\n",
    "                      })\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Write a  program to scrape data for first 10 job results for Data scientist Designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Days_ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GroundTruth</td>\n",
       "      <td>21d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algoscale</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARKTECH CONSULTANCY</td>\n",
       "      <td>6d</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>24h</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>7d</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>24h</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ank Aha</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Days_ago Rating\n",
       "0               Genpact       1d    3.8\n",
       "1            IHS Markit       9d    4.1\n",
       "2           GroundTruth      21d    3.3\n",
       "3  Gauge Data Solutions      24h    3.1\n",
       "4             Algoscale      24h    3.7\n",
       "5  MARKTECH CONSULTANCY       6d      -\n",
       "6       SearchUrCollege      24h      -\n",
       "7              Techlive       7d      5\n",
       "8       Priority Vendor      24h      4\n",
       "9               Ank Aha      24h    4.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.glassdoor.co.in/Job/index.htm')\n",
    "# search job position and location\n",
    "driver.find_element_by_id('KeywordSearch').send_keys('Data Scientist')\n",
    "driver.find_element_by_id('LocationSearch').clear()\n",
    "driver.find_element_by_id('LocationSearch').send_keys('Noida')\n",
    "driver.find_element_by_class_name('gd-btn-mkt').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# extracting  'company', 'no. of days ago' and 'rating' for first 10 jobs\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "jobs = bs.find_all('ul', attrs ={'class':'jlGrid hover p-0'})\n",
    "company = [j.text for i in jobs for j in i.find_all('a','css-10l5u4p e1n63ojh0 jobLink')[:10]]\n",
    "ndays_ago = [j.text for i in jobs for j in i.find_all('div','d-flex align-items-end pl-std css-mi55ob')[:10]]\n",
    "\n",
    "ratings = []\n",
    "for i in jobs:\n",
    "       for j in i.find_all('div','d-flex flex-column css-fbt9gv e1rrn5ka2')[:10]:\n",
    "            if j.text != '':\n",
    "                ratings.append(j.text)\n",
    "            else:\n",
    "                ratings.append('-')\n",
    "                \n",
    "    \n",
    "job_df = pd.DataFrame({'Company': company,\n",
    "                       'Days_ago': ndays_ago,\n",
    "                       'Rating': ratings})\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: Write a program to scrape the salary data for Data Scientist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Mininum_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>No. of salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹445K</td>\n",
       "      <td>₹11,495K</td>\n",
       "      <td>₹ 12,49,514</td>\n",
       "      <td>13 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹571K</td>\n",
       "      <td>₹2,200K</td>\n",
       "      <td>₹ 11,19,272</td>\n",
       "      <td>9 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹580K</td>\n",
       "      <td>₹2,700K</td>\n",
       "      <td>₹ 6,88,601</td>\n",
       "      <td>8 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹468K</td>\n",
       "      <td>₹1,595K</td>\n",
       "      <td>₹ 7,80,664</td>\n",
       "      <td>8 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹496K</td>\n",
       "      <td>₹1,138K</td>\n",
       "      <td>₹ 7,71,320</td>\n",
       "      <td>8 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹360K</td>\n",
       "      <td>₹1,000K</td>\n",
       "      <td>₹ 5,90,406</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹708K</td>\n",
       "      <td>₹1,557K</td>\n",
       "      <td>₹ 13,21,601</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹784K</td>\n",
       "      <td>₹1,250K</td>\n",
       "      <td>₹ 9,96,446</td>\n",
       "      <td>6 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹614K</td>\n",
       "      <td>₹1,676K</td>\n",
       "      <td>₹ 9,27,677</td>\n",
       "      <td>6 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OYO</td>\n",
       "      <td>₹960K</td>\n",
       "      <td>₹1,863K</td>\n",
       "      <td>₹ 14,00,000</td>\n",
       "      <td>5 salaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company Mininum_salary Maximum_salary  \\\n",
       "0                       Delhivery          ₹445K       ₹11,495K   \n",
       "1                       Accenture          ₹571K        ₹2,200K   \n",
       "2                             IBM          ₹580K        ₹2,700K   \n",
       "3              Ericsson-Worldwide          ₹468K        ₹1,595K   \n",
       "4              Valiance Solutions          ₹496K        ₹1,138K   \n",
       "5       Tata Consultancy Services          ₹360K        ₹1,000K   \n",
       "6              UnitedHealth Group          ₹708K        ₹1,557K   \n",
       "7  Cognizant Technology Solutions          ₹784K        ₹1,250K   \n",
       "8                      Innovaccer          ₹614K        ₹1,676K   \n",
       "9                             OYO          ₹960K        ₹1,863K   \n",
       "\n",
       "  Average_salary No. of salaries  \n",
       "0    ₹ 12,49,514     13 salaries  \n",
       "1    ₹ 11,19,272      9 salaries  \n",
       "2     ₹ 6,88,601      8 salaries  \n",
       "3     ₹ 7,80,664      8 salaries  \n",
       "4     ₹ 7,71,320      8 salaries  \n",
       "5     ₹ 5,90,406      7 salaries  \n",
       "6    ₹ 13,21,601      7 salaries  \n",
       "7     ₹ 9,96,446      6 salaries  \n",
       "8     ₹ 9,27,677      6 salaries  \n",
       "9    ₹ 14,00,000      5 salaries  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "# search job position and location\n",
    "driver.find_element_by_id('KeywordSearch').send_keys('Data Scientist')\n",
    "driver.find_element_by_id('LocationSearch').clear()\n",
    "driver.find_element_by_id('LocationSearch').send_keys('Noida')\n",
    "driver.find_element_by_class_name('gd-btn-mkt').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# extracting 'company', 'average salary','minimum salary','maximum salary' and 'no. of salaries' for first 10 jobs\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "company = [i.text for i in driver.find_elements_by_xpath('//div[@class = \"d-flex\"]/div[2]/p[2]')[:10]]\n",
    "avg_sal = [i.text for i in driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong')[:10]]\n",
    "min_sal = [i.text for i in driver.find_elements_by_xpath('//div[@class= \"col-3 offset-1 d-none d-md-block\" ]/div/div[2]/span[1]')[:10]]\n",
    "max_sal = [i.text for i in driver.find_elements_by_xpath('//div[@class= \"col-3 offset-1 d-none d-md-block\" ]/div/div[2]/span[2]')[:10]]\n",
    "n_sal = [i.text for i in driver.find_elements_by_xpath('//p[@class= \"css-1uyte9r css-1kuy7z7 m-0 \"]')[:10]]\n",
    "\n",
    "job_sal_df = pd.DataFrame({'Company': company,\n",
    "                       'Mininum_salary': min_sal,\n",
    "                       'Maximum_salary': max_sal,\n",
    "                       'Average_salary': avg_sal,\n",
    "                       'No. of salaries':n_sal})\n",
    "job_sal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6 : Program to  scrape data of  sunglasses listings on flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function\n",
    "def flipkart_products(product):\n",
    "    # initializing web driver and webpage\n",
    "    driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "    driver.get('https://www.flipkart.com/')\n",
    "    print('loading.............','\\n')\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/button').click() # closing pop ups\n",
    "    # seach for given product\n",
    "    driver.find_element_by_class_name('_3704LK').send_keys(product)\n",
    "    driver.find_element_by_class_name('L0Z3Pu').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # loop to scape all product related data for each page till page 3\n",
    "    brand = []\n",
    "    product = []\n",
    "    price = []\n",
    "    discount = []\n",
    "    page = 1\n",
    "    end_page = 3\n",
    "    nxt = driver.find_element_by_class_name('_1LKTO3')\n",
    "    while page <= end_page:\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        item_info = bs.find_all('div', attrs ={'class':'E2-pcE _1q8tSL'})\n",
    "        for i in item_info:\n",
    "\n",
    "            for j in i.find_all('div','_2WkVRV'):\n",
    "                brand.append(j.text)\n",
    "\n",
    "            for k in i.find_all('a','IRpwTa'):\n",
    "                product.append(k.text)\n",
    "\n",
    "            for l in i.find_all('div','_30jeq3'):\n",
    "                price.append(l.text)\n",
    "\n",
    "        for i in bs.find_all('div','_25b18c')[:40]:\n",
    "            if i.find('div','_3Ay6Sb') is not None:\n",
    "                discount.append(i.text[-7:])\n",
    "            else:\n",
    "                discount.append('-')\n",
    "\n",
    "        print('Data extracted for page:',page,'\\n')\n",
    "\n",
    "        if page == end_page:\n",
    "            break\n",
    "        else:    \n",
    "            nxt.click()\n",
    "            print('loading.............','\\n')\n",
    "            time.sleep(5)\n",
    "            page += 1\n",
    "\n",
    "    glasses_df = pd.DataFrame({'Brand': brand,\n",
    "                              'Product_description': product,\n",
    "                              'Price': price,\n",
    "                              'Discount':discount})   \n",
    "    return glasses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading............. \n",
      "\n",
      "Data extracted for page: 1 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 2 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹403</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Gradient, UV Protection Over-sized ...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹188</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Shahs collections</td>\n",
       "      <td>Polarized Round Sunglasses (50)</td>\n",
       "      <td>₹99</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>dannilo</td>\n",
       "      <td>Others Round Sunglasses (Free Size)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Polaroid</td>\n",
       "      <td>Others Round Sunglasses (49)</td>\n",
       "      <td>₹3,510</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Brand                                Product_description  \\\n",
       "0       ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "1       ROZZETTA CRAFT  Polarized, Gradient, UV Protection Over-sized ...   \n",
       "2       FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...   \n",
       "3       FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...   \n",
       "4           Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...   \n",
       "..                 ...                                                ...   \n",
       "115  Shahs collections                    Polarized Round Sunglasses (50)   \n",
       "116         Phenomenal  Polarized, UV Protection Retro Square Sunglass...   \n",
       "117            dannilo                Others Round Sunglasses (Free Size)   \n",
       "118         Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...   \n",
       "119           Polaroid                       Others Round Sunglasses (49)   \n",
       "\n",
       "      Price Discount  \n",
       "0      ₹403  79% off  \n",
       "1      ₹404  88% off  \n",
       "2      ₹199  84% off  \n",
       "3      ₹188  87% off  \n",
       "4      ₹379  81% off  \n",
       "..      ...      ...  \n",
       "115     ₹99  80% off  \n",
       "116    ₹269  73% off  \n",
       "117    ₹179  82% off  \n",
       "118    ₹399  80% off  \n",
       "119  ₹3,510  35% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using user-defined function 'flipkart_products' for scraping sunglasses data\n",
    "flipkart_products(product = 'sunglasses' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted for page: 1\n",
      "Data extracted for page: 2\n",
      "Data extracted for page: 3\n",
      "Data extracted for page: 4\n",
      "Data extracted for page: 5\n",
      "Data extracted for page: 6\n",
      "Data extracted for page: 7\n",
      "Data extracted for page: 8\n",
      "Data extracted for page: 9\n",
      "Data extracted for page: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️Its awesome mobile phone in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Iphone 11 black 64gb is really a cool phone 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Although it’s an iPhone, it doesn’t give anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Apple i Phone is the best phone available in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>use outside gives a outstanding experience ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Delightful</td>\n",
       "      <td>Just the display held it from being a 5star ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating              Review  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5    Perfect product!   \n",
       "3       5  Highly recommended   \n",
       "4       5    Perfect product!   \n",
       "..    ...                 ...   \n",
       "95      3                Nice   \n",
       "96      3                Nice   \n",
       "97      5           Just wow!   \n",
       "98      5           Brilliant   \n",
       "99      4          Delightful   \n",
       "\n",
       "                                          Full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "2   It’s a must buy who is looking for an upgrade ...  \n",
       "3   iphone 11 is a very good phone to buy only if ...  \n",
       "4   Value for money❤️❤️Its awesome mobile phone in...  \n",
       "..                                                ...  \n",
       "95  Iphone 11 black 64gb is really a cool phone 1....  \n",
       "96  Although it’s an iPhone, it doesn’t give anyth...  \n",
       "97  Apple i Phone is the best phone available in t...  \n",
       "98  use outside gives a outstanding experience ......  \n",
       "99  Just the display held it from being a 5star ph...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "time.sleep(5)\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART')\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[1]\").click()\n",
    "time.sleep(5)\n",
    "review_summary = []\n",
    "rating = []\n",
    "full_review = []\n",
    "\n",
    "# loop for extracting product reviews and ratings for each page till page 10\n",
    "page = 1\n",
    "end_page = 10\n",
    "while page <= end_page:\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    review = bs.find('div','_1YokD2 _3Mn1Gg col-9-12')\n",
    "    print('Data extracted for page:',page)\n",
    "    for i in review:\n",
    "        for j in i.find_all('p','_2-N8zT'):\n",
    "            review_summary.append(j.text)\n",
    "        for k in i.find_all('div','t-ZTKy'):\n",
    "                 full_review.append(k.text)\n",
    "\n",
    "    for i in driver.find_elements_by_class_name('_27M-vq'):\n",
    "             rating.append(i.text[0])\n",
    "\n",
    "    if page == 1:\n",
    "        driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[11]\").click()\n",
    "        \n",
    "    elif  1 < page < end_page :\n",
    "         driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[12]\").click()\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "    page+= 1\n",
    "            \n",
    "review_df = pd.DataFrame({'Rating':rating,\n",
    "                          'Review': review_summary,\n",
    "                          'Full_review':full_review})\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: Scrape data of  sneakers from flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading............. \n",
      "\n",
      "Data extracted for page: 1 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 2 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khadim's</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹581</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹579</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹224</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shoes Bank</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Adiso</td>\n",
       "      <td>Casual sneakers,outdoors,dancingshoes Sneakers...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹348</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>MOU</td>\n",
       "      <td>Zar Check Sneakers Sneakers For Men</td>\n",
       "      <td>₹529</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Claptrap</td>\n",
       "      <td>Mesh Walking Casual Sneakers Shoes for Men And...</td>\n",
       "      <td>₹426</td>\n",
       "      <td>14% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Black Bottom</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Par...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product_description Price  \\\n",
       "0        Khadim's                                   Sneakers For Men  ₹581   \n",
       "1          Bonexy                                   Sneakers For Men  ₹379   \n",
       "2          Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...  ₹579   \n",
       "3          Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...  ₹224   \n",
       "4      Shoes Bank     White Sneaker For Men's/Boy's Sneakers For Men  ₹349   \n",
       "..            ...                                                ...   ...   \n",
       "115         Adiso  Casual sneakers,outdoors,dancingshoes Sneakers...  ₹399   \n",
       "116    D-SNEAKERZ  Casual , Partywear Sneakers Shoes For Men's An...  ₹348   \n",
       "117           MOU                Zar Check Sneakers Sneakers For Men  ₹529   \n",
       "118      Claptrap  Mesh Walking Casual Sneakers Shoes for Men And...  ₹426   \n",
       "119  Black Bottom  Fashion Outdoor Canvas Casual Light Weight Par...  ₹379   \n",
       "\n",
       "    Discount  \n",
       "0    61% off  \n",
       "1    62% off  \n",
       "2    70% off  \n",
       "3    55% off  \n",
       "4    65% off  \n",
       "..       ...  \n",
       "115  60% off  \n",
       "116  65% off  \n",
       "117  47% off  \n",
       "118  14% off  \n",
       "119  62% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using user-defined function 'flipkart_products' for scraping sneakers data\n",
    "flipkart_products(product = 'sneakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9: Write a program to scrape 100 shoes data from myntra.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men NMD R1Sneakers</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>8396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Yung- 1 Sneakers</td>\n",
       "      <td>7149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>6013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>6496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>6013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Running Shoes</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women HOVR Rise Training Shoes</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Woven Design Slip-On Sneakers</td>\n",
       "      <td>7194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Derbyacs</td>\n",
       "      <td>8994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                  Product_description  Price\n",
       "0   ADIDAS Originals                   Men NMD R1Sneakers   6499\n",
       "1               Nike           Men AIR ZOOM Running Shoes   8396\n",
       "2   ADIDAS Originals                 Men Yung- 1 Sneakers   7149\n",
       "3       Kenneth Cole                Men Textured Sneakers   6013\n",
       "4               Nike        PEGASUS FLYEASE Running Shoes   6496\n",
       "..               ...                                  ...    ...\n",
       "95      Kenneth Cole                Men Textured Sneakers   6013\n",
       "96              Puma                 Unisex Running Shoes   6499\n",
       "97      UNDER ARMOUR       Women HOVR Rise Training Shoes   8499\n",
       "98              Geox  Women Woven Design Slip-On Sneakers   7194\n",
       "99              Geox          Men Leather Formal Derbyacs   8994\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "time.sleep(3)\n",
    "# selecting color and price range\n",
    "driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div').click()\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# loop for extracting shoe data for each page till page 2 \n",
    "brand = []\n",
    "product = []\n",
    "price = []\n",
    "page = 1\n",
    "end_page = 2\n",
    "while page <= end_page:\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    shoe_info = bs.find_all('div', attrs ={'class':'product-productMetaInfo'})\n",
    "    \n",
    "    for i in shoe_info:\n",
    "        brand.append(i.find('h3','product-brand').text)\n",
    "        product.append(i.find('h4','product-product').text)\n",
    "        price.append(i.find('div','product-price').text.split('Rs.')[1])\n",
    "\n",
    "    if page == end_page:\n",
    "        break\n",
    "    else:\n",
    "        driver.find_element_by_xpath('//ul[@class = \"pagination-container\"]/li[12]/a').click()\n",
    "        time.sleep(5)\n",
    "        page += 1\n",
    "shoe_df = pd.DataFrame({'Brand': brand,\n",
    "                       'Product_description': product,\n",
    "                       'Price': price})\n",
    "shoe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10:Write a program to srape first 10 laptop data from amazon.in for processor type i7 and i9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS VivoBook Ultra 15 (2020) Intel Core i7-11...</td>\n",
       "      <td>₹69,984.00</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...</td>\n",
       "      <td>₹81,990.00</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...</td>\n",
       "      <td>₹1,49,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td>₹85,990.00</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) HP EliteBook FOLIO 9480M Laptop (Cor...</td>\n",
       "      <td>₹24,490.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Lenovo ThinkPad High Performance 12....</td>\n",
       "      <td>₹36,699.00</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>₹95,840.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 10th Gen14-i...</td>\n",
       "      <td>₹84,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asus ROG Strix G15 Core i7 10th Gen - (8 GB/51...</td>\n",
       "      <td>₹84,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>₹2,69,294.00</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product         Price Rating\n",
       "0  ASUS VivoBook Ultra 15 (2020) Intel Core i7-11...    ₹69,984.00    3.6\n",
       "1  Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...    ₹81,990.00    3.6\n",
       "2  ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...  ₹1,49,990.00      -\n",
       "3  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...    ₹85,990.00    4.1\n",
       "4  (Renewed) HP EliteBook FOLIO 9480M Laptop (Cor...    ₹24,490.00      -\n",
       "5  (Renewed) Lenovo ThinkPad High Performance 12....    ₹36,699.00    3.4\n",
       "6  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...    ₹95,840.00      5\n",
       "7  Lenovo ThinkPad E14 Intel Core i7 10th Gen14-i...    ₹84,990.00      -\n",
       "8  Asus ROG Strix G15 Core i7 10th Gen - (8 GB/51...    ₹84,990.00      -\n",
       "9  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  ₹2,69,294.00    2.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(3)\n",
    "# search for product\n",
    "driver.find_element_by_id('twotabsearchtextbox').send_keys('Laptop')\n",
    "driver.find_element_by_xpath('//div[@class = \"nav-search-submit nav-sprite\"]/span/input').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# check whether 'NoSuchElementException' occurs while selecting processor type and to handle exception if it exists.\n",
    "try:\n",
    "    driver.find_element_by_xpath('//li[@aria-label =\"Intel Core i7\"]/span/a/div/label').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//li[@aria-label =\"Intel Core i9\"]/span/a/div/label').click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "# loop for extracting first 10 laptops data \n",
    "product = []\n",
    "price = []\n",
    "rating = []\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "product_url = bs.find_all('a', attrs ={'class':'a-link-normal a-text-normal'})\n",
    "for i in product_url[:10]:\n",
    "    driver.get('https://www.amazon.in/'+i['href'])\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    product.append(bs.find('span','a-size-large product-title-word-break').text.replace('\\n',''))\n",
    "    try:\n",
    "        price.append(bs.find('span','a-size-medium a-color-price priceBlockBuyingPriceString').text.replace('\\xa0',''))\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            price.append(bs.find('span','a-size-medium a-color-price priceBlockDealPriceString').text.replace('\\xa0',''))\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                price.append(bs.find('span','a-size-base a-color-price').text.replace('\\xa0',''))\n",
    "            except AttributeError:\n",
    "                price.append('-')\n",
    "    try:\n",
    "        rating.append(bs.find('span','a-size-medium a-color-base').text[:-9])\n",
    "    except AttributeError:\n",
    "        rating.append('-')\n",
    "        \n",
    "laptop_df = pd.DataFrame({'Product':product,\n",
    "                          'Price': price,\n",
    "                          'Rating': rating})\n",
    "laptop_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
